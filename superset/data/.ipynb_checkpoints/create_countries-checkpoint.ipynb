{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord = pd.read_csv('./shape013_polygons.csv', \n",
    "            header = None, \n",
    "            index_col = 0)\n",
    "\n",
    "coord.columns = ['latitude_min', 'latitude_max', \n",
    "                     'longitude_min', 'longitude_max', \n",
    "                     'code', 'source', 'STAT_LEVL']\n",
    "\n",
    "coord[\"lat_avg\"] = (coord.latitude_max+coord.latitude_min)/2\n",
    "\n",
    "coord[\"lgt_avg\"] = (coord.longitude_max+coord.longitude_min)/2\n",
    "\n",
    "coord['code'] = coord.code.apply(lambda x : x.split('.')[2])\n",
    "\n",
    "coord = coord[['code', 'lat_avg', 'lgt_avg']]\n",
    "\n",
    "coordinates_dict = coord.set_index('code').to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for coordinates\n",
    "pd.DataFrame(coordinates_dict).reset_index().rename({'index':'NUTS_code', 'lat_avg':'lat', 'lgt_avg':'lng'}, \n",
    "                                                    axis = 1).to_csv('nuts_coord.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./NUTS_RG_60M_2016_4326.json', 'rb') as f:\n",
    "    nuts3 = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = [\n",
    "    {'name': j['properties']['NUTS_NAME'], \n",
    "     'cca2':j['properties']['NUTS_ID'], \n",
    "     'lat':np.round(coordinates_dict['lat_avg'].get(j['properties']['NUTS_ID']),2), \n",
    "     'lng':np.round(coordinates_dict['lgt_avg'].get(j['properties']['NUTS_ID']),2),\n",
    "     'cca3': j['properties']['NUTS_ID'],\n",
    "     'cioc': j['properties']['NUTS_ID'],\n",
    "    } for j in nuts3['objects']['NUTS_RG_60M_2016_4326']['geometries'] \n",
    "    if coordinates_dict['lat_avg'].get(j['properties']['NUTS_ID'], 'null') is not 'null'\n",
    "                                       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('countries.json', 'w') as f:\n",
    "    json.dump(countries, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.dialects.mysql import INTEGER, VARCHAR, FLOAT, TINYINT, DOUBLE\n",
    "from functools import reduce\n",
    "import countries   # ../superset/data\n",
    "import json\n",
    "\n",
    "import logging\n",
    "\n",
    "################\n",
    "## PARAMETERS ##\n",
    "################\n",
    "\n",
    "logging.basicConfig(\n",
    "        filename ='keep_statistics_etl.log',\n",
    "        level = logging.INFO,\n",
    "        format='%(asctime)s %(funcName)s : %(levelname)s : %(message)s'\n",
    "        )\n",
    "\n",
    "# DB\n",
    "\n",
    "SQL_SOURCE_DB_USER = 'root'\n",
    "SQL_SOURCE_DB_PSSW = 'keepKalm'\n",
    "SQL_SOURCE_HOST = 'vpckeep2.arakne'\n",
    "SQL_SOURCE_PATH = (\"mysql://{0}:{1}@{2}/keep_drupal_burp\"\n",
    "        .format(SQL_SOURCE_DB_USER, SQL_SOURCE_DB_PSSW, SQL_SOURCE_HOST)\n",
    "        )\n",
    "\n",
    "SQL_DESTINATION_DB_USER = 'root'\n",
    "SQL_DESTINATION_DB_PSSW = 'keepKalm'\n",
    "SQL_DESTINATION_HOST = 'localhost'\n",
    "SQL_DESTINATION_PATH = (\"mysql://{0}:{1}@{2}/keep_drupal_burp\"\n",
    "        .format(SQL_DESTINATION_DB_USER, SQL_DESTINATION_DB_PSSW, SQL_DESTINATION_HOST)\n",
    "        )\n",
    "\n",
    "tables = [\n",
    "        'keep_programme',\n",
    "        'kamut_project', 'kamut_sotoip',\n",
    "        'keep_programme_type',\n",
    "        'kamut_partner',\n",
    "        'taxonomy_term_data',\n",
    "        'field_data_field_strand',\n",
    "        'field_data_field_source',\n",
    "        'field_data_field_keywords',\n",
    "        'keep_nuts',\n",
    "        'field_data_field_total_budget',\n",
    "        'field_data_field_total_budget_2',\n",
    "        'field_data_field_total_budget_ta',\n",
    "        'field_data_field_them_prior',\n",
    "        'field_data_field_them_obj',\n",
    "        'field_data_field_strat_obj',\n",
    "        'field_data_field_spec_obj',\n",
    "        'field_data_field_spec_objs',\n",
    "        'field_data_field_prog_prior',\n",
    "        'field_data_field_lead_partner',\n",
    "        'field_data_field_inv_prior',\n",
    "        ]\n",
    "\n",
    "#############\n",
    "# FUNCTIONS #\n",
    "#############\n",
    "\n",
    "def extractThematic(field_data_keywords, taxonomy_term_data):\n",
    "    '''\n",
    "    Ref: keep_drupal_burp db\n",
    "    Function that extracts thematic given tables field_data_keywords\n",
    "    and taxonomy_term_data\n",
    "    '''\n",
    "    df_thematics = field_data_field_keywords.copy()\n",
    "    idx_project_entity = df_thematics[df_thematics.entity_type == 'kamut_project'].index\n",
    "    df_thematics = df_thematics.loc[idx_project_entity]\n",
    "    df_thematics.rename(\n",
    "            {'entity_id':'project_id', 'field_keywords_tid':'tid'},\n",
    "            axis = 1,\n",
    "            inplace = True\n",
    "            )\n",
    "    df_thematics = df_thematics[['project_id', 'tid']]\n",
    "    return df_thematics.set_index('tid').join(\n",
    "            taxonomy_term_data.set_index('tid'),\n",
    "            how='left'\n",
    "            ).reset_index(drop = True)\n",
    "\n",
    "def extractProgramType(field_data_field_strand,\n",
    "        field_data_field_source, taxonomy_term_data):\n",
    "    '''\n",
    "    Ref: keep_drupal_burp db\n",
    "    Function that extracts Programme Type given tables field_data_field_strand,\n",
    "    field_data_field_source and taxonomy_term_data.\n",
    "    '''\n",
    "    # strand\n",
    "    idx_programme = field_data_field_strand[\n",
    "            field_data_field_strand.entity_type == 'keep_programme'\n",
    "            ].index\n",
    "    strand = field_data_field_strand.loc[idx_programme]\n",
    "    strand = strand[['field_strand_tid', 'entity_id']]\n",
    "    strand.rename(\n",
    "                {'field_strand_tid':'taxonomy_term', 'entity_id':'programme_id'},\n",
    "                axis = 1,\n",
    "                inplace = True\n",
    "            )\n",
    "    idx_strand_term = field_data_field_strand[\n",
    "            field_data_field_strand.entity_type =='taxonomy_term'\n",
    "            ].index\n",
    "    strand_term = field_data_field_strand.loc[idx_strand_term]\n",
    "    strand_term = strand_term[['field_strand_tid', 'entity_id']]\n",
    "    strand_term.rename(\n",
    "                {'entity_id':'tid', 'field_strand_tid':'taxonomy_term'},\n",
    "                axis = 1,\n",
    "                inplace = True\n",
    "            )\n",
    "    idx_programme = field_data_field_source[\n",
    "            field_data_field_source.entity_type == 'keep_programme'\n",
    "            ].index\n",
    "\n",
    "    # source\n",
    "    source = field_data_field_source.loc[idx_programme]\n",
    "    source = source[['field_source_tid', 'entity_id']]\n",
    "    source.rename(\n",
    "                {'field_source_tid':'taxonomy_term', 'entity_id':'programme_id'},\n",
    "                axis = 1,\n",
    "                inplace = True\n",
    "            )\n",
    "    idx_source_term = field_data_field_source[\n",
    "                field_data_field_source.entity_type =='taxonomy_term'\n",
    "            ].index\n",
    "    source_term = field_data_field_source.loc[idx_source_term]\n",
    "    source_term = source_term[['field_source_tid', 'entity_id']]\n",
    "    source_term.rename(\n",
    "                {'entity_id':'tid', 'field_source_tid':'taxonomy_term'},\n",
    "                axis = 1,\n",
    "                inplace = True\n",
    "            )\n",
    "\n",
    "    source_tid = source.merge(source_term, on = 'taxonomy_term')[\n",
    "        ['programme_id', 'tid']\n",
    "        ]\n",
    "\n",
    "    strand_tid = strand.merge(strand_term, on = 'taxonomy_term')[\n",
    "        ['programme_id', 'tid']]\n",
    "\n",
    "    program_type_tid = source_tid.merge(strand_tid,\n",
    "                on = ['programme_id', 'tid'])\n",
    "\n",
    "    program_type = program_type_tid.merge(\n",
    "            taxonomy_term_data,\n",
    "            on = 'tid')[['programme_id', 'name']]\n",
    "    program_type.rename(\n",
    "            {'name':'program_type'},\n",
    "            axis  = 1,\n",
    "            inplace = True)\n",
    "    return program_type\n",
    "\n",
    "def commitTable(df_table, table_name, engine,\n",
    "        dtype_flag = False, dtype_dic = None ):\n",
    "    table_name = 'superset_'+table_name\n",
    "    if not dtype_flag:\n",
    "        df_table.to_sql(\n",
    "            con = engine.connect(),\n",
    "            name = table_name,\n",
    "            if_exists = 'replace',\n",
    "            index = False,\n",
    "            )\n",
    "    else:\n",
    "        df_table.to_sql(\n",
    "            con = engine.connect(),\n",
    "            name = table_name,\n",
    "            if_exists = 'replace',\n",
    "            index = False,\n",
    "            dtype = dtype_dic\n",
    "        )\n",
    "\n",
    "def merger(tableList):\n",
    "    return reduce(\n",
    "                lambda x,y : pd.merge(x,y, how = 'outer', on = 'project_id'),\n",
    "                tableList)\n",
    "\n",
    "def getTables(table_list, engine):\n",
    "    cnx = engine.connect()\n",
    "    out = {}\n",
    "    for table_name in table_list:\n",
    "        out[table_name] = pd.read_sql_table(table_name, cnx)\n",
    "    cnx.close()\n",
    "    return out\n",
    "\n",
    "############\n",
    "##  MAIN  ##\n",
    "############\n",
    "\n",
    "logging.info('Start elaborating database')\n",
    "logging.info('Create SQL engines')\n",
    "\n",
    "mysql_engine_destination = create_engine(SQL_DESTINATION_PATH)\n",
    "mysql_engine_source = create_engine(SQL_SOURCE_PATH)\n",
    "\n",
    "dfs = getTables(tables, mysql_engine_source)\n",
    "\n",
    "logging.info('Start elaboration')\n",
    "\n",
    "### SELECT TABLES FEATURES\n",
    "## keep_programme\n",
    "keep_programme = dfs['keep_programme'][\n",
    "                ['id', 'type', 'title', 'use_for_statistics', 'is_visible']\n",
    "        ].copy()\n",
    "keep_programme = keep_programme[(keep_programme.use_for_statistics == 1)]\n",
    "\n",
    "## keep_project\n",
    "kamut_project = dfs['kamut_project'][\n",
    "                ['pid', 'programme_id', 'budget', 'project_start', 'project_end']\n",
    "        ].copy()\n",
    "\n",
    "# Replace 0 with nan to avoid misleading time conversion\n",
    "kamut_project.project_start = kamut_project.project_start.replace(0,np.nan)\n",
    "kamut_project.project_end = kamut_project.project_end.replace(0,np.nan)\n",
    "\n",
    "## keep_programme_type\n",
    "keep_programme_type = dfs['keep_programme_type'][['type', 'period']].copy()\n",
    "\n",
    "## kamut_partner\n",
    "kamut_partner = dfs['kamut_partner'][\n",
    "        ['pid',\n",
    "        'project_id',\n",
    "        'partnership_type',\n",
    "        'country',\n",
    "        'region_0',\n",
    "        'region_1',\n",
    "        'region_2',\n",
    "        'region_3',\n",
    "        'is_ext_nuts',\n",
    "        'geocoding_x',\n",
    "        'geocoding_y']].copy()\n",
    " # geocoding_y is latitude, geocoding_x longitude\n",
    "\n",
    "## kamut_sotoip\n",
    "kamut_sotoip = dfs['kamut_sotoip'][\n",
    "        ['programme_id',\n",
    "        'thematic_objective',\n",
    "        'investment_priority']\n",
    "    ].copy()\n",
    "\n",
    "\n",
    "# zfill string to sort correctly\n",
    "kamut_sotoip['thematic_objective'] = (\n",
    "            '('+\n",
    "            kamut_sotoip.thematic_objective.str.extract(r'([0-9]+)',\n",
    "            expand = False).str.zfill(2)+')' +\n",
    "            kamut_sotoip.thematic_objective.str.replace('(\\([0-9]+\\))', '')\n",
    "        )\n",
    "\n",
    "kamut_sotoip['investment_priority'] = (\n",
    "            '(' +\n",
    "            kamut_sotoip.investment_priority.str.extract(r'([0-9]+)',\n",
    "            expand = False).str.zfill(2) +\n",
    "            kamut_sotoip.investment_priority.str.replace('(\\([0-9]+)', '')\n",
    "        )\n",
    "\n",
    "# Getting max length for thematic objective and investment_priority fields\n",
    "varchar_max = np.max(kamut_sotoip.iloc[:,[1,2]].fillna('o').applymap(\n",
    "    lambda x : np.array(len(x))).values\n",
    "    )\n",
    "\n",
    "kamut_sotoip.drop_duplicates(inplace = True)\n",
    "kamut_sotoip = kamut_sotoip[~kamut_sotoip.isnull()[\n",
    "        ['thematic_objective', 'investment_priority']\n",
    "    ].all(axis = 1)]\n",
    "\n",
    "taxonomy_term_data = dfs['taxonomy_term_data'][['tid', 'name']].copy()\n",
    "\n",
    "## field_data_field_strand\n",
    "field_data_field_strand = dfs['field_data_field_strand'][\n",
    "            ['entity_type', 'bundle','entity_id', 'field_strand_tid']\n",
    "        ].copy()\n",
    "\n",
    "## field_data_field_source\n",
    "field_data_field_source = dfs['field_data_field_source'][\n",
    "            ['entity_type', 'bundle', 'entity_id', 'field_source_tid']\n",
    "        ].copy()\n",
    "\n",
    "## field_data_field_keywords\n",
    "field_data_field_keywords = dfs['field_data_field_keywords'][\n",
    "            ['entity_type', 'bundle', 'entity_id', 'field_keywords_tid']\n",
    "        ].copy()\n",
    "\n",
    "## keep_nuts\n",
    "keep_nuts = dfs['keep_nuts'][\n",
    "            ['entity_id', 'nuts_id', 'country_code', 'parent', 'description']\n",
    "        ].copy()\n",
    "\n",
    "### TABLES ELABORATION ###\n",
    "\n",
    "## Projects metric\n",
    "projectId_programmeId = kamut_project[['pid', 'programme_id']].copy()\n",
    "projectId_programmeId.rename({'pid':'project_id'}, axis = 1, inplace = True)\n",
    "\n",
    "## ProjectID-Thematics\n",
    "projectId_thematic = extractThematic(field_data_field_keywords, taxonomy_term_data)\n",
    "projectId_thematic.rename({'name':'thematic'}, axis = 1, inplace = True)\n",
    "projectId_thematic.dropna(inplace = True)\n",
    "\n",
    "## ProjectID - Country/NUTS/Partners\n",
    "\n",
    "projectId_countryNutsPartners = kamut_partner[\n",
    "            [\n",
    "                'project_id',\n",
    "                'pid',\n",
    "                'country',\n",
    "                'region_0',\n",
    "                'region_1',\n",
    "                'region_2',\n",
    "                'region_3',\n",
    "                'geocoding_x',\n",
    "                'geocoding_y',\n",
    "                'partnership_type',\n",
    "                'is_ext_nuts'\n",
    "            ]\n",
    "        ].copy()\n",
    "\n",
    "projectId_countryNutsPartners.rename(\n",
    "        {\n",
    "            'pid':'partner_id',\n",
    "            'country':'country_name',\n",
    "            'region_0':'nuts_0',\n",
    "            'region_1':'nuts_1',\n",
    "            'region_2':'nuts_2',\n",
    "            'region_3':'nuts_3',\n",
    "            'geocoding_x':'partner_lgt',\n",
    "            'geocoding_y':'partner_lat',\n",
    "            'partnership_type':'is_leader'},\n",
    "        axis = 1,\n",
    "        inplace = True)\n",
    "\n",
    "\n",
    "projectId_countryNutsPartners.drop_duplicates(inplace = True)\n",
    "\n",
    "projectId_countryNutsPartners['cca2'] = projectId_countryNutsPartners.nuts_0.replace(\n",
    "            {'UK':'GB', 'EL':'GR'}\n",
    "        )\n",
    "projectId_countryNutsPartners['lat'] = projectId_countryNutsPartners.cca2.dropna().apply(\n",
    "        lambda x : countries.get('cca2', x)['lat']\n",
    "        )\n",
    "projectId_countryNutsPartners['lng'] = projectId_countryNutsPartners.cca2.dropna().apply(\n",
    "        lambda x : countries.get('cca2', x)['lng']\n",
    "        )\n",
    "\n",
    "\n",
    "projectId_countryNutsPartners = projectId_countryNutsPartners[\n",
    "        ~projectId_countryNutsPartners.project_id.isnull()\n",
    "        ]\n",
    "\n",
    "## ProjectID - Programming Period\n",
    "programmeID_programmingPeriod = keep_programme[['id', 'type']].merge(\n",
    "        keep_programme_type,\n",
    "        on = 'type'\n",
    "        )[['id', 'period']]\n",
    "programmeID_programmingPeriod.rename(\n",
    "        {'id':'programme_id'},\n",
    "        axis = 1,\n",
    "        inplace = True)\n",
    "\n",
    "projectId_period = programmeID_programmingPeriod.merge(\n",
    "        projectId_programmeId,\n",
    "        on = 'programme_id'\n",
    "        )[['project_id', 'period']]\n",
    "\n",
    "## ProjectID - Programme Names\n",
    "projectId_programmeName = keep_programme.rename({'id':'programme_id'}, axis = 1).merge(\n",
    "            kamut_project[['pid', 'programme_id']],\n",
    "            on = 'programme_id'\n",
    "            )[['pid', 'title']].rename(\n",
    "                        {'pid':'project_id', 'title':'programme_name'},\n",
    "                        axis = 1\n",
    "                        )\n",
    "\n",
    "## ProjectID - Program Type\n",
    "programmeId_programType = extractProgramType(\n",
    "        field_data_field_strand,\n",
    "        field_data_field_source,\n",
    "        taxonomy_term_data\n",
    "        )\n",
    "\n",
    "projectId_programType = programmeId_programType.merge(\n",
    "        projectId_programmeId,\n",
    "        on = 'programme_id')[['project_id', 'program_type']]\n",
    "\n",
    "## ProjectID - Thematic Objectives and Investement Priorities\n",
    "programmeId_thObj_invPri = kamut_sotoip.drop_duplicates()\n",
    "\n",
    "mask_all_nan = programmeId_thObj_invPri[\n",
    "            ['thematic_objective', 'investment_priority']\n",
    "            ].applymap(lambda x : x == None).all(axis = 1)\n",
    "\n",
    "programmeId_thObj_invPri = programmeId_thObj_invPri[~mask_all_nan]\n",
    "\n",
    "projectId_thObj_invPrio = programmeId_thObj_invPri.merge(\n",
    "        projectId_programmeId,\n",
    "        on = 'programme_id'\n",
    "        )[['project_id','thematic_objective', 'investment_priority']]\n",
    "\n",
    "# zfill string to sort correctly\n",
    "projectId_thObj_invPrio['thematic_objective'] = (\n",
    "        '('+\n",
    "        projectId_thObj_invPrio.thematic_objective.str.extract(r'([0-9]+)',\n",
    "        expand = False\n",
    "        ).str.zfill(2)+')' +\n",
    "         projectId_thObj_invPrio.thematic_objective.str.replace('(\\([0-9]+\\))', ''))\n",
    "\n",
    "projectId_thObj_invPrio['investment_priority'] = (\n",
    "        '(' +\n",
    "        projectId_thObj_invPrio.investment_priority.str.extract(r'([0-9]+)',\n",
    "        expand = False\n",
    "        ).str.zfill(2)+projectId_thObj_invPrio.investment_priority.str.replace('(\\([0-9]+)', ''))\n",
    "\n",
    "# Getting max length for thematic objective and investment_priority fields\n",
    "varchar_max = np.max(\n",
    "        projectId_thObj_invPrio.iloc[:,[1,2]].fillna('o').applymap(\n",
    "            lambda x : np.array(len(x))\n",
    "            ).values)\n",
    "\n",
    "## ProjectID - Budget\n",
    "\n",
    "projectId_budget = kamut_project[['pid', 'budget']].copy()\n",
    "projectId_budget.rename({'pid':'project_id'}, axis = 1, inplace = True)\n",
    "\n",
    "## ProjectID - StartEnd\n",
    "projectId_startEnd = kamut_project[['pid', 'project_start', 'project_end']].copy()\n",
    "projectId_startEnd.dropna(inplace = True)\n",
    "projectId_startEnd.rename({'pid':'project_id'}, axis = 1, inplace = True)\n",
    "\n",
    "### FURTHER ELABORATION AND DB COMMIT\n",
    "\n",
    "## MASTER ##\n",
    "tables_to_merge = [\n",
    "        projectId_thematic,\n",
    "        projectId_countryNutsPartners,\n",
    "        projectId_period,\n",
    "        projectId_programmeId,\n",
    "        projectId_programmeName,\n",
    "        projectId_programType,\n",
    "        projectId_thObj_invPrio,\n",
    "        projectId_startEnd,\n",
    "        projectId_budget\n",
    "        ]\n",
    "\n",
    "master = merger(tables_to_merge)\n",
    "master.drop_duplicates(inplace = True)\n",
    "\n",
    "# Set duplicated budget to zero\n",
    "master['budget'][master[['project_id', 'thematic', 'period', 'budget']].duplicated()] = 0\n",
    "\n",
    "name_map_dic = keep_nuts[['nuts_id', 'description']].set_index(\"nuts_id\").to_dict()['description']\n",
    "\n",
    "master[['nuts_0', 'nuts_1', 'nuts_2']] = master[['nuts_0', 'nuts_1', 'nuts_2']].fillna('nan')\n",
    "master[['nuts_0', 'nuts_1', 'nuts_2']] = master[['nuts_0', 'nuts_1', 'nuts_2']].applymap(\n",
    "        lambda x : '['+x+'] - '+name_map_dic[x].lower().capitalize() if x != 'nan' else np.nan\n",
    "        )\n",
    "logging.info('Commit to superset_master')\n",
    "# Commit Table on DESTINATION_DB\n",
    "\n",
    "coord_dict = pd.read_csv('./nuts_coord.csv', index_col = 0).set_index('NUTS_code').to_dict()\n",
    "\n",
    "master['nuts0_lat'] = master['nuts_0'].str.slice(1,3).apply(lambda x : coord_dict['lat'].get(x, np.nan))\n",
    "master['nuts0_lng'] = master['nuts_0'].str.slice(1,3).apply(lambda x : coord_dict['lng'].get(x, np.nan))\n",
    "\n",
    "master['nuts1_lat'] = master['nuts_1'].str.slice(1,4).apply(lambda x : coord_dict['lat'].get(x, np.nan))\n",
    "master['nuts1_lng'] = master['nuts_1'].str.slice(1,4).apply(lambda x : coord_dict['lng'].get(x, np.nan))\n",
    "\n",
    "master['nuts2_lat'] = master['nuts_2'].str.slice(1,5).apply(lambda x : coord_dict['lat'].get(x, np.nan))\n",
    "master['nuts2_lng'] = master['nuts_2'].str.slice(1,5).apply(lambda x : coord_dict['lng'].get(x, np.nan))\n",
    "\n",
    "master['nuts3_lat'] = master['nuts_3'].apply(lambda x : coord_dict['lat'].get(x, np.nan))\n",
    "master['nuts3_lng'] = master['nuts_3'].apply(lambda x : coord_dict['lng'].get(x, np.nan))\n",
    "\n",
    "# TODO esplicitare lo schema di export della tabella\n",
    "\n",
    "commitTable(\n",
    "         master,\n",
    "         'master',\n",
    "         mysql_engine_destination,\n",
    "         dtype_flag = True,\n",
    "         dtype_dic = {\n",
    "             'project_id':INTEGER,\n",
    "             'thematic':VARCHAR(255),\n",
    "             'partner_id':INTEGER,\n",
    "             'country_name':VARCHAR(255),\n",
    "             'nuts_0':VARCHAR(255),\n",
    "             'nuts_1':VARCHAR(255),\n",
    "             'nuts_2':VARCHAR(255),\n",
    "             'nuts_3':VARCHAR(255),\n",
    "             'partner_lgt':DOUBLE,\n",
    "             'partner_lat':DOUBLE,\n",
    "             'is_leader':TINYINT(4),\n",
    "             'is_ext_nuts':TINYINT(4),\n",
    "             'cca2':VARCHAR(255),\n",
    "             'lat':DOUBLE,\n",
    "             'lng':DOUBLE,\n",
    "             'period':VARCHAR(255),\n",
    "             'programme_id':INTEGER,\n",
    "             'programme_name':VARCHAR(255),\n",
    "             'program_type':VARCHAR(255),\n",
    "             'thematic_objective':VARCHAR(varchar_max),\n",
    "             'investment_priority':VARCHAR(varchar_max),\n",
    "             'project_start':DOUBLE,\n",
    "             'project_end':DOUBLE,\n",
    "             'budget':DOUBLE, \n",
    "             'nuts0_lat': DOUBLE,\n",
    "             'nuts0_lng': DOUBLE,\n",
    "             'nuts1_lat': DOUBLE,\n",
    "             'nuts1_lng': DOUBLE,\n",
    "             'nuts2_lat': DOUBLE,\n",
    "             'nuts2_lng': DOUBLE,\n",
    "             'nuts3_lat': DOUBLE,\n",
    "             'nuts3_lng': DOUBLE,\n",
    "             }\n",
    "         )\n",
    "\n",
    "INDICES_QUERY = \"ALTER TABLE superset_master ADD INDEX(project_id), ADD INDEX(thematic),  ADD INDEX(partner_id), ADD INDEX(country_name), ADD INDEX(nuts_0), ADD INDEX(nuts_1), ADD INDEX(nuts_2), ADD INDEX(nuts_3), ADD INDEX(period), ADD INDEX(programme_id), ADD INDEX(programme_name), ADD INDEX(program_type), ADD INDEX(thematic_objective), ADD INDEX(investment_priority);\"\n",
    "\n",
    "\n",
    "with mysql_engine_destination.connect() as con:\n",
    "        con.execute(INDICES_QUERY)\n",
    "\n",
    "logging.info('Done!')\n",
    "\n",
    "\n",
    "\n",
    "logging.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
